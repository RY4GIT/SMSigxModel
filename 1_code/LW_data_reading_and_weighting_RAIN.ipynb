{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code read and calculate weights on the rainfall dataset. I realized the errors in my previous code later, so the previous code may not work now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yrs = ['0609', '0911', '1113']\n",
    "temp_path = rf'G:\\Shared drives\\Ryoko and Hilary\\SMSigxModel\\analysis\\0_data\\Little Washita\\data_ars_temp'\n",
    "out_path = r'G:\\Shared drives\\Ryoko and Hilary\\SMSigxModel\\analysis\\2_data_input\\LittleWashita'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) First, concatinate all data within a folder and store them in the temporary folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_yr in range(len(data_yrs)):\n",
    "    # Extract the dates and sensor numbers from the file names\n",
    "    folder_path = rf'G:\\Shared drives\\Ryoko and Hilary\\SMSigxModel\\analysis\\0_data\\Little Washita\\data_ars_{data_yrs[n_yr]}'\n",
    "    # Get a list of all files in the folder\n",
    "    file_list = os.listdir(folder_path)\n",
    "    # file_list[1].split('a')[1][0:3]\n",
    "\n",
    "    dates = [file.split('a')[0] for file in file_list if file != 'README']\n",
    "    sensors = [file.split('a')[1][0:3] for file in file_list if file != 'README']\n",
    "    \n",
    "    # %%\n",
    "    unique_dates = list(set(dates))\n",
    "    unique_sensors = list(set(sensors))\n",
    "    # %%\n",
    "    # Create lists to store the dataframes for each sensor\n",
    "    sensor_dataframes = {}\n",
    "\n",
    "    # for sensor in unique_sensors:\n",
    "    #     # Create an empty dataframe for the sensor\n",
    "    #     sensor_dataframes[sensor] = pd.DataFrame()\n",
    "    for i, sensor in enumerate(unique_sensors):\n",
    "        sensor_dataframes[sensor] = pd.DataFrame()\n",
    "        print(f'Currently processing sensor {i+1}/{len(unique_sensors)}')\n",
    "        \n",
    "        for date in tqdm(unique_dates):\n",
    "            # Extract the date and sensor number from the file name\n",
    "            file_name = os.path.join(folder_path, date + 'a' + sensor + '.txt')\n",
    "            \n",
    "            # Read the file as a pandas dataframe\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, delim_whitespace=True, header=3)\n",
    "                \n",
    "                df['date'] = pd.to_datetime(date, format='%Y%m%d')\n",
    "                \n",
    "                mask = df['HR'] == 24\n",
    "                df.loc[mask, 'date'] = df.loc[mask, 'date'] + pd.Timedelta(days=1)\n",
    "                df.loc[mask, 'HR'] = '00'\n",
    "                \n",
    "                df['datetime'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['HR'].astype(str).str.zfill(2) + ':'+ df['MN'].astype(str).str.zfill(2), format='%Y-%m-%d %H:%M')\n",
    "                \n",
    "                df.loc[df[\"QRN\"] != \"g\", \"RAIN\"] = np.nan\n",
    "                df[\"RAIN\"] = df[\"RAIN\"].diff() # Convert cumulative to original\n",
    "\n",
    "                df = df[[\"datetime\", \"RAIN\"]]\n",
    "\n",
    "                # Concatenate the dataframe into the dataframe for the sensor\n",
    "                sensor_dataframes[sensor] = pd.concat([sensor_dataframes[sensor], df], axis=0, ignore_index=True)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        # Save the dataframe for the sensor to a CSV file\n",
    "        file_name = 'ars' + data_yrs[n_yr] + '_a' + sensor + '_rain.csv'\n",
    "        file_path = os.path.join(temp_path, file_name)\n",
    "        sensor_dataframes[sensor].to_csv(file_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Then, concatinete sensors for the all period. Drop nan values, make time interval regular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_path_2 = rf'G:\\Shared drives\\Ryoko and Hilary\\SMSigxModel\\analysis\\0_data\\Little Washita\\data_ars_temp2'\n",
    "temp_path = rf'G:\\Shared drives\\Ryoko and Hilary\\SMSigxModel\\analysis\\0_data\\Little Washita\\data_ars_temp'\n",
    "# # Get the ones that has record from 2006\n",
    "# sensors = [file.split('0609_a')[1][0:3] for file in file_list if (file != 'README') and ('0609' in file)]\n",
    "n_yr = 0\n",
    "file_list = os.listdir(temp_path)\n",
    "print(file_list)\n",
    "sensors = [file.split('_a')[1][0:3] for file in file_list if (file != 'README') and ('0609' in file)]\n",
    "unique_sensors = list(set(sensors))\n",
    "print(unique_sensors)\n",
    "len(unique_sensors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
